{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pandas Exercise\n",
    "\n",
    "When working on real world data tasks, you'll quickly realize that a large portion of your time is spent manipulating raw data into a form that you can actually work with, a process often called *data munging* or *data wrangling*.  Different programming langauges have different methods and packages to handle this task, with varying degrees of ease, and luckily for us, Python has an excellent one called Pandas which we will be using in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and working with Data Frames\n",
    "The Data Frame is perhaps the most important object in Pandas and Data Science in Python, providing a plethora of functions for common data tasks.  Using only Pandas, do the following exercises.\n",
    "\n",
    "1. Download the [free1.csv](https://vincentarelbundock.github.io/Rdatasets/csv/Zelig/free1.csv) from the [R Data Repository](https://vincentarelbundock.github.io/Rdatasets/datasets.html) and save it to the same directory as this notebook.  Then import into your environment as a Data Frame.  Now read [free2.csv](https://vincentarelbundock.github.io/Rdatasets/csv/Zelig/free2.csv) directly into a Data Frame from the URL.\n",
    "1. Combine your `free1` Data Frame with `free2` into a single Data Frame, named `free_data`, and print the first few rows to verify that it worked correctly.  From here on out, this combined Data Frame is what we will be working with. (Hint: use the `concat` method).\n",
    "1. Print the last 10 rows.\n",
    "1. Rename the first column (currently unamed), to `id`.  Print the column names to verify that it worked correctly.\n",
    "1. What are the number of rows and columns of the Data Frame?\n",
    "1. What are the data types of each column?  Can quantities like the mean be calculated for each columm?  If not, which one(s) and why?\n",
    "1. Print out the first 5 rows of the `country` column.\n",
    "1. How many unique values are in the `country` column?\n",
    "1. Print out the number of occurences of each unique value in the `country` column.\n",
    "1. Summarize the dataframe.\n",
    "1. Were all columns included in the summary?  If not, print the summary again, forcing this column to appear in the result.\n",
    "1. Print rows 100 to 110 of the `free1` Data Frame.\n",
    "1. Print rows 100 to 110 of only the first 3 columns in `free1` using only indices.\n",
    "1. Create and print a list containing the mean and the value counts of each column in the data frame **except** the `country` column.\n",
    "1. Create a Data Frame, called `demographics`, using only the columns `sex`, `age`, and `educ` from the `free1` Data Frame.  Also create a Data Frame called `scores`, using only the columns `v1`, `v2`, `v3`, `v4`, `v5`, `v6` from the `free1` Data Frame\n",
    "1. Loop through each row in `scores` and grab the largest value, in the `v_` columns, found in each row and store your results in two lists containing the value and column name it came from.  For example, row `0` is\n",
    "```python\n",
    "{'v1': 4, 'v2': 3, 'v3': 3, 'v4': 5, 'v5': 3, 'v6': 4}\n",
    "```\n",
    "the values\n",
    "```python\n",
    "('v4', 5)\n",
    "```\n",
    "should be added to your two lists.\n",
    "1. Create a new Data Frame with columns named `cat` and `score` from your results in part (16), for the column with the largest score and the actual score respectively.\n",
    "1. Using the Data Frame created in part (17), print the frequency of each column being the max score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting, Filtering, and Grouping data\n",
    "Most of the time, we'll want to rearrange the data a bit, include only certain values in our analysis, or put the data into useful groups.  Pandas provides syntax and many functions to do this.\n",
    "\n",
    "Using only Pandas, do the following exercises.\n",
    "\n",
    "1. Using the `free1.csv` downloaded above, import it as a Data Frame named `free_data`, rename the first column to `id`, and print the first few rows.\n",
    "1. Sort `free_data` by `country`, `educ`, and then by `age` in decending order, modifying the original Data Frame.\n",
    "1. Create a new Data Frame called `uni` containing only rows from `free_data` which indicate that the person attended university or graduate school.  Print the value counts for each country.\n",
    "1. Create a list of three Data Frames for those who are less than 25 years old, between 25 and 50 years old, and older than 50.\n",
    "1. Using a for loop, create a list of 3 Data Frames each containing only one of the 3 countries.\n",
    "1. Create a list of age categories, labled 0, 1, and 2 for each row for the three groups made in part (4).  Attach this list to the `free_data` dataframe as a column named `age_cat`.\n",
    "1. Print the mean for all columns for each `age_cat` using `groupby`.\n",
    "1. Print the mean education for each `age_cat` using `groupby`.\n",
    "1. Print summary statistics for each column for those with an education greater than or equal to 5, grouped by `age_cat`.\n",
    "1. Which of the vignette has the largest mean score for each education level?  What about the median?\n",
    "1. Which country would you say has the most freedom of speech?  Be sure to justify your answer quantitatively.\n",
    "1. Is there a difference of opinion between men and women regarding freedom of speech?  If any, does this difference manifest itself accross the different countries?  Accross education levels?  Be sure to justify your answers quantiatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging, Indexes, and  `Apply()`\n",
    "Much of the power of Data Sciences comes from the ability to join together datasets from very different sources.  One could be interested in seeing if there is a relationship between housing prices and prevalence of infectious disease in a given ZIP code for example.  This task is often referred to as a *merge* or *join*.\n",
    "\n",
    "Every Pandas Data Frame has an *index*.  Indices in Pandas are a bit of a complex topic, but for the time being consider them to be a unique identifier for each row in a Data Frame.  When performing joins and manipulating Data Frames, it is important to remember that your task may require the creation or change of the Data Frame's index.  For more extensive reading on this topic, consult the [Pandas Documentation](http://tomaugspurger.github.io/modern-3-indexes.html).\n",
    "\n",
    "And lastly, if you are coming from a programming background like C/C++ or Java, you are likely very accustomed to operating on arrays and lists using for loops.  Often this is how you will want to work with Data Frames in Python, but Pandas also provides functionality for functional like programming by utilizing the `Apply()` function.  This is similar to the `apply` family of functions in R and the `Map()` and related functions in Lisp.  Making use of `Apply()` in Python can make your code more concise, readable, and faster when performing operations on an entire Data Frame.\n",
    "\n",
    "Using on Pandas, perform the following exercises.\n",
    "\n",
    "1. Using the free1.csv downloaded above, import it as a Data Frame named `free_data` and rename the first column to id.\n",
    "1. Create a dataframe named `free_sub`, consisting of the `id`, `country`, and `y` columns from `free_data`.\n",
    "1. Create a new Data Frame called `ed_level`, consisting of the `id` and three categories of education levels, labeled `high`, `med`, and `low`, for ranges of your choosing.  Do this using a for loop.\n",
    "1. Merge `free_sub` and `ed_level` together.  Which column should the merge be performed on?  Do this using both the `concat()` and `merge()` functions.\n",
    "1. Use the `append()` function to join together `free_sub` and `ed_level`.  Are the results the same as in part (4)?  If not, how could you reproduce the result `append()` by using `concat()` or `merge()`?\n",
    "1. Use numpy to generate two lists 100 random floats labeled `y1` and `y2`.  Now create a sequence of integers on the range 0-100 labeled `x1` and a sequence of integers on the range 50-150 labeled `x2`.  Create two DataFrames, `dat1` and `dat2` consisting of `x1` and `y1`, and `x2` and `y2` respectively, but having labels `x, y1`, and `x, y2`.  Use `merge()` to join these two Data Frames together, on `x`, using both an inner and outer join.  What is the difference between the two joins?\n",
    "1. Create a Data Frame, called `scores` consising of only the `y` and `v_` columns from `free_data`.\n",
    "1. Using a for loop(s), compute the sum and mean for each column in `scores`.\n",
    "1. Using the `apply()` function, compute the sum and mean for each column in `scores`.\n",
    "1. Using the `apply()` function, label each column in `scores` as either `high`, `med`, or `low` by first computing the mean for each column and assigning the categories at values of your choosing.  Do this by writing a single function you can call with `apply()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series\n",
    "In many situations you may not know the relationship between two variables but you do know that there ought to be one.  Take for example the daily price of beef and grain.  It is reasonable to assume that there exists *some*, perhaps even  a causal, relationship between these two, but due to the complexity of the phenomenon, and the vast number of underlying latent variables involved (fuel price, politics, famine, etc...), you likely have little hope to uncover such a relationship in a reasonable amount of time.  However, you do know that these two variables *are* related in time and may exibit some pattern that repeats itself in time.  Identifying these types of patterns is called Time Series Analysis and sequencing your data such that each data point is represented as a unique point in time is called a Time Series.  The canonical example of a Time Series is, of course, stock market data which is what we will be using for this exercise\n",
    "\n",
    "Do the following exercises.\n",
    "\n",
    "1. Create a `start` and `end` `datetime` object, starting at a date of your choosing and ending today.\n",
    "1. For three stocks of your choosing, put their symbols into a list and use Quadl to [retrieve their data](https://www.quandl.com/tools/python) for the time frame you created in part (1).  Print the results.\n",
    "1. Create a Data Frame called `stock_open` for the open prices of the stocks you retrieved in part (2).  Print the first few rows.\n",
    "1. Compute the total, average, and maximum price for each stock weekly.\n",
    "1. For each stock, return the weeks for which the opening stock price was greater than the yearly daily average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "# Get Apple Stock\n",
    "# import quandl as q\n",
    "# data = q.get(\"WIKI/AAPL\", start_date=\"2001-12-31\", end_date=\"2005-12-31\")\n",
    "# data.tail()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
