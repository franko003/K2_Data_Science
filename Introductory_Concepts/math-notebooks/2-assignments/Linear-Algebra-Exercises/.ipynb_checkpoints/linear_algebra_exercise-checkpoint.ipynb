{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Linear Algebra\n",
    "Although its name may sound harmless, Linear Algebra is by no means a trivial branch of mathematics, and the deeper you dive into Data Science and Statistics, the more often you will encounter its concepts.  In this exercise, we'll start with some basic operations on matrices and vectors, then move onto Eigenvalues and Eigenvectors, and conclude with some Matrix Decompositions.\n",
    "\n",
    "## Vectors and Matrices\n",
    "1. Create a $2\\times2$ matrix $\\textbf{A}$ and a column vector $\\vec{v}$.  Now compute the matrix products $\\textbf{A}\\vec{v}$ and $\\vec{v}\\textbf{A}$.  Did both operations work?  Why or why not?\n",
    "1. Using $\\vec{v}$ above, compute the inner, or dot, product, $\\vec{v} \\cdot \\vec{v}$.  Is this quantity reminiscent of another vector quantity?\n",
    "1. Create 3 matrices $\\textbf{A}$, $\\textbf{B}$, $\\textbf{C}$ of dimension $2\\times2$, $3\\times2$, and $2\\times3$ respectively such that $$\\textbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\textbf{B} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6\\end{bmatrix} \\textbf{C} = \\begin{bmatrix} 1 & 2 & 3\\\\ 4 & 5 & 6 \\end{bmatrix}$$ and perform the following multiplications, stating the final dimensions of each: $\\textbf{AA}$, $\\textbf{AB}$, $\\textbf{AC}$, $\\textbf{BB}$, $\\textbf{BA}$, $\\textbf{BC}$, $\\textbf{CC}$, $\\textbf{CA}$, $\\textbf{CB}$.  Comment on your results.\n",
    "1. Using $\\textbf{A}$ and $\\textbf{B}$ above, compute $(\\textbf{BA})^T$ and $\\textbf{A}^T \\textbf{B}^T$.  What can you say about your results?\n",
    "1. Using $\\textbf{A}$, $\\textbf{B}$, and $\\textbf{C}$ above, compute the following sums: $\\textbf{A+A}$, $\\textbf{A+B}$, $\\textbf{A+C}$, $\\textbf{B+B}$, $\\textbf{B+A}$, $\\textbf{B+C}$, $\\textbf{C+C}$, $\\textbf{C+A}$, $\\textbf{C+B}$.  Comment on your results.\n",
    "1. Construct three matrices $\\textbf{I}_A$, $\\textbf{I}_B$, and $\\textbf{I}_C$ such that $\\textbf{I}_A\\textbf{A} = \\textbf{A}$, $\\textbf{I}_B\\textbf{B} = \\textbf{B}$, and $\\textbf{I}_C\\textbf{C} = \\textbf{C}$.\n",
    "1. Construct three matrices $\\textbf{A}^{-1}$, $\\textbf{B}^{-1}$, and $\\textbf{C}^{-1}$ such that $\\textbf{A}^{-1}\\textbf{A} = \\textbf{I}_A$, $\\textbf{B}^{-1}\\textbf{B} = \\textbf{I}_B$, and $\\textbf{C}^{-1}\\textbf{C} = \\textbf{I}_C$.  Comment on your results. **Hint** This may not always be possible!\n",
    "1. Using $\\textbf{A}^{-1}$ compute $(\\textbf{A}^{-1})^T(^{-1})$ and comment on your results.\n",
    "1. Using $\\textbf{A}$, $\\textbf{B}$, and $\\textbf{C}$, compute the determinant of each.  Comment on your results.\n",
    "1. Construct a square ($2\\times2$) matrix, $\\textbf{D}$,that is not invertible.\n",
    "1. How would you go about solving the equation $\\textbf{A}\\vec{x} = 0$, using $\\textbf{A}$ as above for an unknown $\\vec{x}$?  Do so and comment on your results.  **Hint** consider parts (6) and (7).\n",
    "1. Using the same method as in part (11), solve the equation $\\textbf{A}\\vec{x} = \\vec{y}$ where $\\vec{y} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$\n",
    "1. Solve the system of equations $$x_0 + 2x_1 = 3$$ $$-x_0 + x_1 = 1$$ using both matrix inversion and built in numpy functions.\n",
    "1. Solve the system of equations $$x_0 + x_1 = 1$$ $$2x_0 + 2x_1 = 2$$ $$-3x_0 + -3x_1 = -3$$ using both matrix inversion and built in numpy functions.  Are these results what you expected?  Comment on your results.\n",
    "1. Solve the system of equations $$x_0 + x_1 = 0$$ $$x_0 + x_1 = 1$$ using both matrix inversion and built in numpy functions.  Are these results what you expected?  Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues and Eigenvectors\n",
    "No discussion of Linear Algebra would be complete without taking a look at Eigenvalues and Eigenvectors.  The root word \"eigen\" comes from the German meaning \"characteristic\", and these values and associated vectors, represent some interesting properties of a given matrix.  Namely, for a given matrix $\\textbf{A}$ and vector $\\vec{v}$, the eigenvalue(s), $\\lambda$, of $\\textbf{A}$, are the $\\lambda$ that satisfy the relationship $$\\textbf{A} \\vec{v} = \\lambda \\vec{v}$$ Keep in mind that $\\lambda$ is a *scalar* quantity, and when you multiply a vector by a scalar quantity, you just scale, or stretch, the vector in space.  Therefore, the above relationship says that the eigenvalues $\\lambda$ of $\\textbf{A}$, and associated eigenvectors $\\vec{v}$, are the vectors that when multiplied by $\\textbf{A}$ just \"stretch\" in space (no rotations).\n",
    "\n",
    "Now that may not sound very special, but the applicability of these concepts cannot be understated.  Eigenvalues and vectors have a tendency to crop up in any mathematically grounded discipline and Data Science is no exception.\n",
    "\n",
    "For a more detailed explanation, see \n",
    "- [Great math formula explanation](http://www.visiondummy.com/2014/03/eigenvalues-eigenvectors/)\n",
    "- [Visual explanation of Eigenvectors and Eigenvalues](http://setosa.io/ev/eigenvectors-and-eigenvalues/)\n",
    "\n",
    "before proceding with the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate a matrix $$\\textbf{A} = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix}$$ and two vectors of your choosing, labeled $\\vec{v}_1$ and $\\vec{v}_2$.  Then compute the vectors $$\\vec{v}_1' = \\textbf{A}\\vec{v}_1$$ $$\\vec{v}_2' = \\textbf{A}\\vec{v}_2$$ And plot all 4 vectors with appropriate labels.  Comment on your results.\n",
    "1. Now compute the eigenvalues and eigenvectors of $\\textbf{A}$, then plot $\\textbf{A}\\vec{v}$ and $\\lambda\\vec{v}$ on seperate plots, where $\\lambda$ is the eigenvalue of $\\textbf{A}$.  Comment on your results.\n",
    "1. How do the results of part (2) differ from part (1)?\n",
    "1. Define a new 3x3 matrix of the form $$\\textbf{A} = \\begin{bmatrix} -2 & -4 & 2 \\\\ -2 & 1 & 2 \\\\ 4 & 2 & 5 \\end{bmatrix}$$ and compute the eigenvalues and vectors.  What can you say about the number of eigenvectors in your results?\n",
    "1. Define a new 3x3 matrix of the form $$\\textbf{B} = \\begin{bmatrix} -2 & -4 & 2 \\\\ -2 & 1 & 2 \\\\ 1 & 2 & -1 \\end{bmatrix}$$ and compute the eigenvalues and vectors.  What can you say about the eigenvalues in your results?  Do they differ from what you saw in part (4)?\n",
    "1. Compute the inverse of $\\textbf{A}$ and $\\textbf{B}$ above.  Comment on your results.\n",
    "1. Compute the determinant of $\\textbf{A}$ and $\\textbf{B}$.  How might your results relate to the eigen values you computed above?\n",
    "1. Consider the rotation matrix $$\\textbf{R} = \\begin{bmatrix} cos(\\theta) & sin(\\theta) \\\\ -sin(\\theta) & cos(\\theta)\\end{bmatrix}$$.  Using a value of $\\theta = 90$, compute the inner product of the columns, $\\textbf{R}^T$, $\\textbf{R}^{-1}$, $det(\\textbf{R})$, and the eigenvalues and eigenvectors.  Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Decomposition\n",
    "Matrix Decomposition can be thought of as rewriting a given matrix as a product of other (and often simpler) matrices.  For example, given a matrix $\\textbf{A}$, one can decompose $\\textbf{A}$ into the following. $$\\textbf{A} = \\textbf{Q} \\Lambda \\textbf{Q}^{-1}$$\n",
    "where $\\textbf{Q}$ is a matrix whose *$i^{th}$* column is the *$i^{th}$* eigenvector of $\\textbf{A}$, and $\\Lambda$ is a matrix containing all of the corresponding eigenvalues on the main diagonal.  Decomposing $\\textbf{A}$ in this manner is called an Eigendecomposition.  Such matrix decompositions, form the basis of many techniques in Data Science and other mathematical disciplines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute the eigenvalues and eigenvectors of matrix $$\\textbf{A} = \\begin{bmatrix} -2 & -4 & 2 \\\\ -2 & 1 & 2 \\\\ 4 & 2 & 5 \\end{bmatrix}$$\n",
    "1. Construct a matrix $\\textbf{Q}$ whose columns are the eigenvectors of $\\textbf{A}$.\n",
    "1. Construct a set of three vectors $\\vec{\\lambda_1} \\dots \\vec{\\lambda_n}$, whose *$n^{th}$* element is the *$n^{th}$* eigenvalue of $\\textbf{A}$ while all other elements are 0.  The second vector, for example, would be $$\\vec{\\lambda_2} = \\begin{bmatrix} 0 \\\\ \\lambda_2 \\\\ 0 \\end{bmatrix}$$\n",
    "1. Now try multiplying various combinations of $\\textbf{A}$, $\\textbf{Q}$, and $\\vec{\\lambda_n}$ together.  What is the relationship among them?\n",
    "1. Solve the relationship you found in part (4) for $\\textbf{A}$ and verify that this is the eigenvalue decomposition.\n",
    "1. Another very useful matrix decomposition is the Singular Value Decomposition (SVD) which is used, for example, in Principal Component Analysis.  A full discussion of this decomposition is beyond the scope of this exercise, but singular values are the square roots of the eigenvalues of $\\textbf{A}\\textbf{A}^T$ (for the real case).  Using numpy, perform a SVD on $\\textbf{A}$ used above, and verify that the values on the main diagonal of the singular matrix are the square roots of the eigenvalues of $\\textbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
